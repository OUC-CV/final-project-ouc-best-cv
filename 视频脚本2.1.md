# OUC-Best-CV 视频脚本 2.1

> 参考视频类型（问答环节的思路来源）：【小米三年就造出这么个SU7？】 https://www.bilibili.com/video/BV1Dw4m127ej/?share_source=copy_web&vd_source=3aa9ee0c4fcf2e52762a44f906c09534
>
> 1.0版本里面的话语比较直白，需要后续修改
>
> 2.0版本努力补齐内容空白

### 开场（2min）

HDRI领域的研究早在上世纪就开始了。虽说这个研究领域经历了时间的洗礼，对长期深入研究计算机视觉领域的人来说可能过于幼稚，但对大学生来说（短换气）刚刚好。【画面：类似于PPT图片一张一张的滑入，图片内容可以是以前的论文、经典的数据集中的图片。可以加入那种像是“信号不好”的视频特效】

【NO SIGNAL】

【念PPT】

该领域虽然已经存在大量的研究，部分技术也日趋成熟，但时至今日，该领域仍有许多创新点值得我们发掘。

那我们能否取长补短，站在巨人的肩膀上，在尽可能多地吸收优秀思路的同时发掘创新点呢？

+ 我们通过查阅大量的文献，查找了HDRI的相关内容。在《基于深度引导与自学习的高动态成像算法》一文中，作者提出了一个基于深度引导与自学习的多曝光图像融合网络MEF-Net；在《Recovering High Dynamic Range Radiance Maps from Photographs》一文中，作者提出了一种从传统成像设备拍摄的照片中恢复高动态范围辐射图的方法，通过用不同的曝光量图片恢复成像过程的响应函数，将多张图片融合成一个高动态范围的亮度图，该论文的作者正是最早提出HDRI技术的Debevec（[How to pronounce Debevec | HowToPronounce.com](https://www.howtopronounce.com/debevec)）；在《基于亮度分区模糊融合的高动态范围成像算法》一文中，作者提出通过将亮度分成两个区间可以使低亮度区域的亮度增加、范围扩大，高亮度区域的亮度减小、范围扩大，从而增大图像的整体对比度，保留色彩和细节信息。参考这些文献，了解到HDRI领域仍然值得我们发掘，最后我们选择融合上述论文中提到的方法。
+ 我们通过搜索网络上的博客，在知乎里看到HDR+的思路，在CSDN里看到“网络也可以具有对齐功能”以及去鬼影的思路，这些思路启发我们思考如何构建更加强大的模型。
+ 我们通过与老师交流，探讨算法实现的可行性。

下面就一起看看我们的代码吧！

### 代码概览（1~2min）

【buling】

滚动代码(.ipynb)，并辅以解释（要提前写好稿子）

PPT里弄上也行



### 问答环节（4~5min，可以适当倾斜更多的视频时长）（可以设计成一个人提问，两个人回答，要活泼一些doge）

【咚咚】

#### Q1 如何评价生成的HDR图像的效果？

+ 生成的图像效果非常好。在保留了图像暗部细节的同时，使得亮部不至于过分曝光。
+ 以我们跑出来的这张结果图为例，树干处的细节清晰可见，并且天空的亮度也不至于过高，整个画面的亮度较为均衡，观感良好。

#### Q2 代码中使用了哪些技术或知识？（删）

+ 一是我们使用了双线性下采样

  双线性下采样是一种常用的图像处理技术，用于减小图像的分辨率。在进行双线性下采样时，原始图像中的每个像素都会被保留，但输出图像的分辨率会降低。这是通过对原始图像中的像素进行加权平均来实现的，以生成输出图像中的新像素。

  双线性下采样使用了原始图像中每个输出像素周围的四个最近邻像素。对于每个输出像素，其值是这四个最近邻像素值的加权平均。这四个最近邻像素通常形成一个矩形区域，因此称为双线性。这种方法可以保持图像的整体结构，并减小图像的尺寸。

+ 二是我们使用了CAN网络![image-20240606145338546](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240606145338546.png)

  CAN网络的全名是Context Aggregation Network，即“上下文聚合网络”。CAN网络采用空洞卷积的方式，在不牺牲图像空间分辨率的情况下，获得更大的感受野。

  CAN网络前6个卷积层包括：卷积核大小为$3×3$，卷积核数目为24的卷积运算和LReLU激活函数。最后一层卷积操作用于生成和输入图像大小一致的权重图，卷积核大小为$1×1$。

+ 三是我们使用了引导滤波联合上采样

  引导滤波的基本原理是利用一个引导图像来指导滤波过程，从而保留图像的结构信息。给定一个输入图像I和一个用于引导的辅助图像P，引导滤波的输出图像Q可以通过$Q(i)=a(i)I(i)+b(i)$计算得到。

  引导滤波可以更好地保留图像细节，有效保持图像的边缘特征，同时计算效率较高。

+ 此外，我们的代码中也使用了融合函数、损失函数、推断函数等，在此不做进一步展开了。

#### Q3 研究过程中遇到了什么问题？是如何解决的？

+ 以前对于PyTorch（大写P大写T）的语法不够熟悉，因此在正式书写代码之前学习了PyTorch的用法，并针对性地学习PyTorch实现反向传播的操作。

+ 在撰写代码的过程中，对迭代次数和学习率等参数的设置不熟悉，参考我们搜集的论文并加以尝试，调整出合适的参数。

+ 在最初进行数据处理时，由于没有使用data loader将数据分成小批次，也就是小的batches，程序经常会发生崩溃。这是因为一次性读入所有数据会占用大量内存，当数据量较大时，内存会爆满。

  后来，当尝试使用GPU进行加速时，由于显存的限制，同样的问题在GPU上也会发生。

  通过改用数据加载器并将数据分批次读取，这个问题得到了改善，因为分批次处理能够有效地减少内存和显存的使用量，从而使程序更加稳定且高效地运行。

+ 一开始对网络结构不熟悉，错误地将下采样、上采样、加权求和写到了网络外面。后续调整代码并将其融合进了网络的内部。

#### Q4 如果该项目继续下去，OUC-Best-CV会对HDRI研究做怎样的拓广？

+ 代码中暂时未引入自适应算子。【换人说】

  自适应算子在遗传算法中通过不断调整选择操作的参数，使得算法能够更好地适应问题的特性。

+ 此外，对参考论文中提出的自学习算法的理解欠佳，需要进行进一步学习。

### 彩蛋（花絮）

+ 录制过程中的失误
+ 日常的素材